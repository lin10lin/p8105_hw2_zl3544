---
title: "p8105_hw2_zl3544"
output: html_document
date: "2024-09-30"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
```{r}
library(tidyverse)
library(readxl)
```

## Problem 1

Using relative path to access the CSV file and clean the data:
```{r, message=FALSE}
NYC_transit_df = 
  read_csv("./data/NYC_Transit_Data.csv", na=c("NA","", ".")) %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
 mutate(
    entry = case_match(
      entry,
      "YES" ~ TRUE,
      "NO" ~ FALSE
    )
  )

```
Then see the head of the selected dataframe:
```{r}
head(NYC_transit_df)
```
In the data cleaning process above, I: Use the relative path to read the csv file, then treat "NA","", "." as missing, then select the variable that worth analyzing in this problem, and clean up variable names, finally, I convert the entry variable from character to a logical variable.

After reading, selecting and cleaning the data, the data set to analyze has 1868 rows and 19 columns. But the data isn't tidy, for the reason that different routes are considered as different variables, these columns contain value information, they can be transformed.

Caculate the distinct stations using distinct function:
```{r, message=FALSE}
distinct_stations= count(distinct(NYC_transit_df, station_name, line))
```
There are `r count(distinct(NYC_transit_df, station_name, line))` distinct stations.

Caculate the ADA compliant stations:
```{r, message=FALSE}
ada_compliant_stations= 
  NYC_transit_df %>% 
  filter(ada==TRUE) %>% 
  distinct(station_name, line) %>% 
  nrow() 
  
```
There are `r filter(NYC_transit_df, ada == "TRUE") %>% distinct(station_name, line) %>% nrow` ADA compliant stations.

Caculate the number of station entrances / exits without vending allow entrance:
```{r, message=FALSE}
no_vending_entry=
  filter(NYC_transit_df, vending=="NO") %>% 
  filter(entry=="TRUE") %>% 
  nrow()
```
Then the proportion of station entrances / exits without vending allow entrance is: `r (filter(NYC_transit_df, vending=="NO") %>% filter(entry=="TRUE") %>% nrow)/(filter(NYC_transit_df, vending=="NO") %>% nrow)`

Reformat data:
```{r}
Tidy_NYC_transit_df =
  NYC_transit_df %>% 
  mutate(
    across(route8:route11, as.character)
  ) %>% 
  pivot_longer(
    route1:route11,
    names_to="route_name",
    names_prefix="route",
    values_to="train",
    values_drop_na=TRUE
  ) 
```
Caculate distinct stations serve the A train using R:
```{r, message=FALSE}
stations_serve_A=
  Tidy_NYC_transit_df %>% 
  filter(train=="A") %>% 
  distinct(line, station_name) %>% 
  nrow() 
```
Distinct stations serve the A train is `r stations_serve_A`.

Caculate the stations that serve the A train, are ADA compliant:
```{r, message=FALSE}
stations_serve_A_ada=
  Tidy_NYC_transit_df %>% 
  filter(train=="A" & ada=="TRUE") %>% 
  distinct(line, station_name) %>% 
  nrow()
```
Among the stations that serve the A train, `r stations_serve_A_ada` are ADA compliant

# Problem 2
## Read and clean the Mr. Trash Wheel sheet:
```{r}
mr_df = read_excel("data/Trash_Wheel_Collection_202409.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N653", na = c("NA", "", ",")) %>% 
  filter(!is.na(Dumpster)) %>% 
  janitor::clean_names() %>% 
  mutate(year = as.character(year)) %>% 
  mutate(trash_wheel = "mr") %>%
  mutate(sports_balls = as.integer(sports_balls), homes_powered = (weight_tons*500/30))
```
## Read and clean the Professor Trash Wheel sheet:
```{r}
pro_trash_df = read_excel("data/Trash_Wheel_Collection_202409.xlsx", sheet = "Professor Trash Wheel", range = "A2:M120", na = c("NA", "", ",")) %>% 
  filter(!is.na(Dumpster)) %>% 
  janitor::clean_names() %>% 
  mutate(year = as.character(year)) %>% 
  mutate(homes_powered = (weight_tons*500/30)) %>% 
  mutate(trash_wheel = "pro_trash")
```
## Read and clean the Gwynnda Trash Wheel sheet:
```{r}
gwy_df = read_excel("data/Trash_Wheel_Collection_202409.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:L265", na = c("NA", "", ",")) %>% 
  filter(!is.na(Dumpster)) %>% 
  janitor::clean_names() %>% 
  mutate(year = as.character(year)) %>% 
  mutate(trash_wheel = "gwy") %>%
  mutate(homes_powered = (weight_tons*500/30))
```
## Combine the datasets
```{r}
tidy_df=
  bind_rows(mr_df, pro_trash_df, gwy_df) %>% 
  janitor::clean_names() %>% 
  relocate(trash_wheel, .before = dumpster) %>% 
  arrange(month, year, date)
head(tidy_df)
```
# Problem 3

## Import the data :
```{r}
bakers_df=
  read_csv("./data/gbb_datasets/bakers.csv", na=c("NA","",".")) %>% 
  janitor::clean_names() %>% 
  separate(baker_name, into = c("baker", "last_name"), sep = " ")
```
```{r}
bakes_df=
  read_csv("./data/gbb_datasets/bakes.csv", na=c("NA","",".")) %>% 
  janitor::clean_names()
```
```{r}
results_df=
  read_csv("./data/gbb_datasets/results.csv",skip=2 ,na=c("NA","",".")) %>% 
  janitor::clean_names()
```
## Correctness and completeness 

Use anti_join function to see how different datasets match, to check the correctness and completeness of the datasets.
```{r}
anti_join(bakes_df, bakers_df, by = "baker", "series")
anti_join(results_df, bakers_df, by = "baker", "series")
anti_join(bakers_df, results_df, by = "baker", "series")
```
The result show that the name Joanne and Jo doesnâ€™t match, both name are from the same series, so I suppose that their are the same people, note as Jo
```{r}
results_df = 
  results_df  %>% 
  mutate(baker = ifelse(baker == "Joanne", "Jo", baker))
bakes_df = 
  bakes_df %>% 
  mutate(baker = ifelse(baker == '"Jo"', "Jo", baker))

anti_join(bakes_df, bakers_df, by = "baker", "series")
anti_join(results_df, bakers_df, by = "baker", "series")
anti_join(bakers_df, results_df, by = "baker", "series")
```
Rename Jo to the results_df and bakes_df, the dataset all match with each other.

## Merge the datasets

Merge the datasets together as one single dataset:
```{r}
final_df=
  results_df %>% 
  left_join(bakes_df, by = c("baker", "series", "episode")) %>% 
  left_join(bakers_df, by=c("baker", "series")) %>% 
  relocate(series, episode, .before="baker")
write.csv(final_df, file = "data/gbb_datasets/final.csv")

  
```
## description 
When seeing the raw data, the baker.csv contains the full name of the baker, however, the bakes.csv and results.csv only include the first name of the baker, so I split the full name of the baker in the baker.csv data. Also, in the results.csv, the first two rows contains no useful information and lead confuse when handle with this data, so I skip the first two rows. Then I use anti_join function to see how different datasets match, then I solve the name that not match. After that, I merge datasets in a order that can include all the information, then relocate the variable order to make it more reasonable to read. Finally, I save the merged dataset to the gbb_dataset file. 

The final dataset consists all the information in the bakers.csv, bakes.csv, results.csv datasets and aviod missing data when merge the datasets together, and the variable is arranged in a logical way, readers can quickly find the baker given the series and episodes and the name of the baker.

## Create table showing winner or star baker

Create a reader-friendly table showing the star baker or winner of each episode in Seasons 5 through 10.
```{r}
star_winner_baker_df=
  final_df %>% 
  filter(series %in% c(5,6,7,8,9,10)) %>% 
  filter(result %in% c("STAR BAKER", "WINNER")) %>% 
  select(series, episode, baker, result) %>% 
  arrange(series, episode, baker)
write.csv(star_winner_baker_df, file = "data/gbb_datasets/star_winner_baker.csv")
```
By viewing the results, we know that at each episode in each season there is a baker rewarded as "STAR BAKER", at the end of each season, there will a "WINNER" of the season. Intuitively, the more a baker rewarded as "STAR BAKER", the more likely that baker will be the "WINNER" of the end of season. We can see from the data that Nadiya from season 6, Candice ini season 7, Sophie in season 8, Rahul in season 9, but the winner of season 10 and 5 didn'n follow this pattern.

## Handle with the data in viewers.csv
```{r, message=FALSE}
viewers_df=
  read_csv("./data/gbb_datasets/viewers.csv", na=c("NA","",".")) %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    cols=series_1:series_10,
    names_to="series",
    names_prefix = "series_",
    values_to = "viewer",
    values_drop_na = TRUE 
  ) %>% 
  relocate(series, .before = episode) %>% 
  arrange(series)
head(viewers_df, 10)
```
The average viewership in Season 1 is `r viewers_df %>% filter(series == "1") %>% pull(viewer) %>% mean()`, the average viewership in Season 5 is `r viewers_df %>% filter(series == "5") %>% pull(viewer) %>% mean()`.